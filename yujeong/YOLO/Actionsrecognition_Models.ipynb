{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ee09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference from: https://github.com/yysijie/st-gcn/tree/master/net\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from Actionsrecognition.Utils import Graph\n",
    "\n",
    "\n",
    "class GraphConvolution(nn.Module):##컨벌루션\n",
    "    \"\"\"The basic module for applying a graph convolution.\n",
    "    Args:\n",
    "        - in_channel: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (int) Size of the graph convolving kernel.\n",
    "        - t_kernel_size: (int) Size of the temporal convolving kernel.\n",
    "        - t_stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - t_padding: (int, optional) Temporal zero-padding added to both sides of\n",
    "            the input. Default: 0\n",
    "        - t_dilation: (int, optional) Spacing between temporal kernel elements. Default: 1\n",
    "        - bias: (bool, optional) If `True`, adds a learnable bias to the output.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math:`(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph adjacency matrix in :math:`(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math:`(N, out_channels, T_{out}, V)`\n",
    "\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 t_kernel_size=1,\n",
    "                 t_stride=1,\n",
    "                 t_padding=0,\n",
    "                 t_dilation=1,\n",
    "                 bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(in_channels,\n",
    "                              out_channels * kernel_size,\n",
    "                              kernel_size=(t_kernel_size, 1),\n",
    "                              padding=(t_padding, 0),\n",
    "                              stride=(t_stride, 1),\n",
    "                              dilation=(t_dilation, 1),\n",
    "                              bias=bias)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = self.conv(x)\n",
    "        n, kc, t, v = x.size()\n",
    "        x = x.view(n, self.kernel_size, kc//self.kernel_size, t, v)\n",
    "        x = torch.einsum('nkctv,kvw->nctw', (x, A))\n",
    "\n",
    "        return x.contiguous()\n",
    "\n",
    "\n",
    "class st_gcn(nn.Module): ##STGCN\n",
    "    #스켈레톤 추출-> 그래프 형태로 만듦 -> joint를 노드로 만들고 edge로 연결\n",
    "    #-> ST-gcn모듈을 통해 feature추출-> /ㅡㅠㅇㅁ\n",
    "    \"\"\"Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (tuple) Size of the temporal convolving kernel and\n",
    "            graph convolving kernel.\n",
    "        - stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - dropout: (int, optional) Dropout rate of the final output. Default: 0\n",
    "        - residual: (bool, optional) If `True`, applies a residual mechanism.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math: `(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph Adjecency matrix in :math: `(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math: `(N, out_channels, T_{out}, V)`\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1,\n",
    "                 dropout=0,\n",
    "                 residual=True):\n",
    "        super().__init__()\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "\n",
    "        self.gcn = GraphConvolution(in_channels, out_channels, kernel_size[1])\n",
    "        self.tcn = nn.Sequential(nn.BatchNorm2d(out_channels),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Conv2d(out_channels,\n",
    "                                           out_channels,\n",
    "                                           (kernel_size[0], 1),\n",
    "                                           (stride, 1),\n",
    "                                           padding),\n",
    "                                 nn.BatchNorm2d(out_channels),\n",
    "                                 nn.Dropout(dropout, inplace=True)\n",
    "                                 )\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = nn.Sequential(nn.Conv2d(in_channels,\n",
    "                                                    out_channels,\n",
    "                                                    kernel_size=1,\n",
    "                                                    stride=(stride, 1)),\n",
    "                                          nn.BatchNorm2d(out_channels)\n",
    "                                          )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        res = self.residual(x)\n",
    "        x = self.gcn(x, A)\n",
    "        x = self.tcn(x) + res\n",
    "\n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class StreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of input channels.\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs. If `None` return pooling features of\n",
    "            the last st-gcn layer instead.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "        or If num_class is `None`: `(N, out_channels)`\n",
    "            :math:`out_channels` is number of out_channels of the last layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, graph_args, num_class=None,\n",
    "                 edge_importance_weighting=True, **kwargs):\n",
    "        super().__init__()\n",
    "        # Load graph.\n",
    "        graph = Graph(**graph_args)\n",
    "        A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # Networks.\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
    "\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        self.st_gcn_networks = nn.ModuleList((\n",
    "            st_gcn(in_channels, 64, kernel_size, 1, residual=False, **kwargs0),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 128, kernel_size, 2, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 256, kernel_size, 2, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs)\n",
    "        ))\n",
    "\n",
    "        # initialize parameters for edge importance weighting.\n",
    "        if edge_importance_weighting:\n",
    "            self.edge_importance = nn.ParameterList([\n",
    "                nn.Parameter(torch.ones(A.size()))\n",
    "                for i in self.st_gcn_networks\n",
    "            ])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        if num_class is not None:\n",
    "            self.cls = nn.Conv2d(256, num_class, kernel_size=1)\n",
    "        else:\n",
    "            self.cls = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # data normalization.\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()  # (N, V, C, T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        x = x.view(N, C, T, V)\n",
    "\n",
    "        # forward.\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x = gcn(x, self.A * importance)\n",
    "\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = self.cls(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TwoStreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Two inputs spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :tuple of math:`((N, 3, T, V), (N, 2, T, V))`\n",
    "        for points and motions stream where.\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`in_channels` is data channels (3 is (x, y, score)), (2 is (mot_x, mot_y))\n",
    "            :math:`T` is a length of input sequence,\n",
    "            :math:`V` is the number of graph nodes,\n",
    "        - Output: :math:`(N, num_class)`\n",
    "    \"\"\"\n",
    "    def __init__(self, graph_args, num_class, edge_importance_weighting=True,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.pts_stream = StreamSpatialTemporalGraph(3, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)\n",
    "        self.mot_stream = StreamSpatialTemporalGraph(2, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)\n",
    "\n",
    "        self.fcn = nn.Linear(256 * 2, num_class)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out1 = self.pts_stream(inputs[0])\n",
    "        out2 = self.mot_stream(inputs[1])\n",
    "\n",
    "        concat = torch.cat([out1, out2], dim=-1)\n",
    "        out = self.fcn(concat)\n",
    "\n",
    "        return torch.sigmoid(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
